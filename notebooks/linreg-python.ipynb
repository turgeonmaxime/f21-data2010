{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971c3314",
   "metadata": {},
   "source": [
    "# Linear regression in Python\n",
    "\n",
    "## Lab Objectives\n",
    "\n",
    "  - Fitting a linear regression model in Python\n",
    "  - Compute evaluation metrics\n",
    "  \n",
    "In the lectures, we focussed on using R for linear regression. This probably what you are most familiar with: we use R in both STAT 1150 and 2150.\n",
    "\n",
    "But as we start building more complex models, and using other approaches, it will make more sense to start fitting these models in Python. In particular, we will make use of the very complete, and very powerful,`scikit-learn` library.\n",
    "\n",
    "We will explore these ideas using the Wage dataset, discussed in the book *Introduction to Statistical Learning*, by James *et al*. If you're interested, it's available online: https://www.statlearning.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbd64da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  age            maritl      race        education        jobclass  \\\n",
      "0  2006   18  1. Never Married  1. White     1. < HS Grad   1. Industrial   \n",
      "1  2004   24  1. Never Married  1. White  4. College Grad  2. Information   \n",
      "2  2003   45        2. Married  1. White  3. Some College   1. Industrial   \n",
      "3  2003   43        2. Married  3. Asian  4. College Grad  2. Information   \n",
      "4  2005   50       4. Divorced  1. White       2. HS Grad  2. Information   \n",
      "\n",
      "           health health_ins   logwage        wage  \n",
      "0       1. <=Good      2. No  4.318063   75.043154  \n",
      "1  2. >=Very Good      2. No  4.255273   70.476020  \n",
      "2       1. <=Good     1. Yes  4.875061  130.982177  \n",
      "3  2. >=Very Good     1. Yes  5.041393  154.685293  \n",
      "4       1. <=Good     1. Yes  4.318063   75.043154  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_csv(\"wage.csv\")\n",
    "# In R: head(data)\n",
    "# In Python: data.head()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f61fa",
   "metadata": {},
   "source": [
    "We want to predict `wage` based on the other variables using linear regression. There are two main packages to do linear regression in Python:\n",
    "\n",
    "  1. `statsmodels`: its interface is very similar to R, based on formulas.\n",
    "  2. `scikit-learn`: the main package for machine learning.\n",
    "  \n",
    "We will look at both packages in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8160ad3",
   "metadata": {},
   "source": [
    "Let's start by spliting our dataset in two pieces: train and test. The dataframe `data` has 3000 rows. We will randomly select 300 of them for the test dataset (i.e. about 10%), and the rest will form the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb261041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 300)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data.sample(n = 300, random_state = 1234)\n",
    "data_train = data.drop(data_test.index)\n",
    "\n",
    "data_train.shape[0], data_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c9b8d",
   "metadata": {},
   "source": [
    "We will import the submodule which uses formula. For linear regression, we need to use the `ols` method. Look at the documentation to see what other models you can fit: https://www.statsmodels.org/stable/api.html#statsmodels-formula-api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b841d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Sun, 12 Dec 2021   Prob (F-statistic):                nan\n",
      "Time:                        19:07:00   Log-Likelihood:                -13954.\n",
      "No. Observations:                2700   AIC:                         2.791e+04\n",
      "Df Residuals:                    2699   BIC:                         2.792e+04\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    112.2312      0.818    137.244      0.000     110.628     113.835\n",
      "==============================================================================\n",
      "Omnibus:                      951.589   Durbin-Watson:                   1.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3827.596\n",
      "Skew:                           1.695   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.747   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Note: The formula is passed as a string\n",
    "fit = smf.ols('wage ~ 1', data = data_train).fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bffd4d",
   "metadata": {},
   "source": [
    "Next, we can use the `predict` method to get predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed84901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1936    112.23118\n",
      "85      112.23118\n",
      "2045    112.23118\n",
      "1230    112.23118\n",
      "2676    112.23118\n",
      "          ...    \n",
      "613     112.23118\n",
      "2236    112.23118\n",
      "2141    112.23118\n",
      "576     112.23118\n",
      "842     112.23118\n",
      "Length: 300, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pred_vals = fit.predict(data_test)\n",
    "print(pred_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f4be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.14792619490065"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "import numpy as np\n",
    "\n",
    "actual_vals = data_test['wage']\n",
    "np.sqrt(np.mean((pred_vals - actual_vals)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7599f01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.44715188917207"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAPE\n",
    "100*np.mean(np.abs((pred_vals - actual_vals)/actual_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8043ab1",
   "metadata": {},
   "source": [
    "Now let's use `age` as a covariate and see if we can improve the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b292f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.95351934958674, 27.93519019628443)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit2 = smf.ols('wage ~ age', data = data_train).fit()\n",
    "pred_vals2 = fit2.predict(data_test)\n",
    "rmse2 = np.sqrt(np.mean((pred_vals2 - actual_vals)**2))\n",
    "mape2 = 100*np.mean(np.abs((pred_vals2 - actual_vals)/actual_vals))\n",
    "\n",
    "rmse2, mape2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38adf7",
   "metadata": {},
   "source": [
    "Just like in the lecture, we can try to add more covariates and see what happens.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Fit a model with age and education as covariates. Compute the RMSE and the MAPE values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c724a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff94677",
   "metadata": {},
   "source": [
    "It's also always a good idea to write a function to avoid code repetition. Let's create a function that computes both the RMSE and the MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9820ba2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_vals3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-09e563327043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_vals3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_vals3' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_metrics(predicted, actual = actual_vals):\n",
    "    rmse = np.sqrt(np.mean((predicted - actual)**2))\n",
    "    mape = 100*np.mean(np.abs((predicted - actual)/actual))\n",
    "    \n",
    "    return rmse, mape\n",
    "\n",
    "compute_metrics(pred_vals3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92563275",
   "metadata": {},
   "source": [
    "Unfortunately, `statsmodels` doesn't allow the `.` notation for selecting all variables, so we need to be explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit4 = smf.ols('wage ~ year+age+maritl+race+education+jobclass+health+health_ins', \n",
    "               data = data_train).fit()\n",
    "pred_vals4 = fit4.predict(data_test)\n",
    "\n",
    "compute_metrics(pred_vals4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591eb375",
   "metadata": {},
   "source": [
    "As we can see, adding all remaining variables didn't lead to a large improvement.\n",
    "\n",
    "**Question**: Why didn't we include the last variable, `logwage`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d374f3",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Fit a linear model with `age`, `maritl`, `education` and `jobclass`. Compute the RMSE and MAPE. Is this model any good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916bca76",
   "metadata": {},
   "source": [
    "## Splines\n",
    "\n",
    "Let's see how we can use splines in this linear model. We will use splines with `age`, the only continuous covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_spl = smf.ols('wage ~ bs(age, knots=(30, 50), degree=3)', \n",
    "                  data_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d448398",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals_spl = fit_spl.predict(data_test)\n",
    "\n",
    "compute_metrics(pred_vals_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33917e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to model with only age\n",
    "compute_metrics(pred_vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e98125",
   "metadata": {},
   "source": [
    "As we can see, it's very similar to how you would do this in R. The main difference is that the formula has to be passed as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430572c2",
   "metadata": {},
   "source": [
    "## Regularized regression\n",
    "\n",
    "Before discussing regularized linear regression in Python, we will quickly show how to perform (classical) linear regression with `scikit-learn`.\n",
    "\n",
    "First, we need to do some data processing. With the formula interface of `statsmodels`, we didn't need to worry about categorical variables: they were automatically transformed into dummy variables. With `scikit-learn`, we need to transform our data ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcae62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Categorical variables have dtype 'object'\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep categorical variables\n",
    "X = data.select_dtypes(include=[object])\n",
    "\n",
    "# There are three steps\n",
    "# 1. Instantiate the encoder\n",
    "# drop = 'first' ensures we have k-1 dummy variables for k levels\n",
    "enc = OneHotEncoder(drop = 'first')\n",
    "# 2. Fit to the data\n",
    "enc.fit(X)\n",
    "# 3. Transform the data\n",
    "X_cat = enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da61e9",
   "metadata": {},
   "source": [
    "Now that we have transformed ourc categorical variables, we will have back age and extract `wage` so that it's its own array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back age\n",
    "age_vec = data['age'].to_numpy().reshape((3000, 1))\n",
    "X = np.hstack((age_vec, X_cat))\n",
    "\n",
    "# Extract wage\n",
    "y = data['wage'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e54975",
   "metadata": {},
   "source": [
    "Now that we have prepared the data and turned them into matrices, let's split it into a training and test dataset. Luckily, `scikit-learn` can help us with this too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=1234\n",
    ")\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc058489",
   "metadata": {},
   "source": [
    "We are finally ready to fit a linear regression model. The workflow is different than with `statsmodels`. First, we need to instantiate a `LinearRegression` object. Then we can use the `fit` and then `predict` methods to fit the model and compute predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "compute_metrics(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The intercept is automatically estimated\n",
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f146c59",
   "metadata": {},
   "source": [
    "**Question**: How would you fit a linear model without the variable `education`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8726a",
   "metadata": {},
   "source": [
    "Now that we know how to fit a linear regression model using `scikit-learn`, fitting a ridge regression model is very similar. Instead of instantiating a `LinearRegression` object, we instantiate a `Ridge` object. Note that it is at instantiation that we need to specificy the hyperparameter `alpha` (what we called `lambda` in class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Create linear regression object\n",
    "regr_ridge = Ridge(alpha = 1.0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred_ridge = regr_ridge.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "compute_metrics(y_pred_ridge, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8c09b",
   "metadata": {},
   "source": [
    "Next, let's fit a lasso regression model. You need to instantiate a `Lasso` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d28052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Create lasso regression object\n",
    "regr_lasso = Lasso(alpha = 1.0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred_lasso = regr_lasso.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "compute_metrics(y_pred_lasso, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a54bc",
   "metadata": {},
   "source": [
    "Lasso regression has the special property that it can provide estimates that are exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_lasso.coef_ == 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
